# 03. Log Parser Modulu - read_historical method

## ğŸ“‹ `read_historical` Metodunun TÉ™yinatÄ±

`read_historical` metodu Zeek-in DNS log faylÄ±ndan tarixi mÉ™lumatlarÄ± oxuyur, strukturlaÅŸdÄ±rÄ±r vÉ™ analiz Ã¼Ã§Ã¼n hazÄ±rlayÄ±r. Bu metod proyektin É™sas mÉ™lumat yÃ¼klÉ™mÉ™ funksionallÄ±ÄŸÄ±nÄ± hÉ™yata keÃ§irir.

## ğŸ—ï¸ Metod Ä°mzasÄ±

```python
def read_historical(self, days: Optional[int] = None) -> bool:
```

**ParametrlÉ™r:**
- `days` (Optional[int]): NeÃ§É™ gÃ¼nlÃ¼k tarixi mÉ™lumat oxunacaq. `None` olarsa bÃ¼tÃ¼n mÃ¶vcud mÉ™lumat oxunur.

**QaytarÄ±r:** `bool` - ÆmÉ™liyyatÄ±n uÄŸurlu olub-olmadÄ±ÄŸÄ±nÄ± gÃ¶stÉ™rir

## ğŸ”§ Metodun Daxili Ä°ÅŸlÉ™mÉ™si

### 1. Fayl ValidasiyasÄ±

```python
if not self._validate_log_file():
    return False
```

**Funksiya:** Log faylÄ±nÄ±n mÃ¶vcudluÄŸunu vÉ™ oxuna bilmÉ™sini yoxlayÄ±r

**ÆhÉ™miyyÉ™ti:** ÆgÉ™r fayl mÃ¶vcud deyilsÉ™, metod dÉ™rhal `False` qaytarÄ±r

### 2. FaylÄ±n OxunmasÄ±

```python
self.df = pd.read_csv(
    self.dns_log_path, 
    comment='#', 
    sep='\t', 
    names=self.DNS_COLUMNS, 
    low_memory=False,
    na_values=['-'],
    keep_default_na=False
)
```

**ParametrlÉ™rin Ä°zahÄ±:**
- `comment='#'`: Zeek ÅŸÉ™rh sÉ™tirlÉ™rini (#'lÉ™ baÅŸlayan) oxuma
- `sep='\t'`: Tab ilÉ™ ayrÄ±lmÄ±ÅŸ sÃ¼tunlar
- `names=self.DNS_COLUMNS`: ÆvvÉ™lcÉ™dÉ™n tÉ™yin edilmiÅŸ sÃ¼tun adlarÄ±
- `low_memory=False`: BÃ¶yÃ¼k fayllar Ã¼Ã§Ã¼n yaddaÅŸ optimizasiyasÄ±
- `na_values=['-']`: '-' iÅŸarÉ™sini NaN kimi qiymÉ™tlÉ™ndir
- `keep_default_na=False`: Pandas'Ä±n default NaN dÉ™yÉ™rlÉ™rini istifadÉ™ etmÉ™

### 3. Timestamp KonversiyasÄ±

```python
if 'ts' in self.df.columns:
    self.df['ts'] = pd.to_datetime(self.df['ts'], unit='s', errors='coerce')
```

**Funksiya:** Unix timestamplÉ™ri Python datetime obyektlÉ™rinÉ™ Ã§evirir

**ParametrlÉ™r:**
- `unit='s'`: SaniyÉ™ É™saslÄ± timestamplÉ™r
- `errors='coerce'`: XÉ™talarÄ± `NaT` (Not a Time) kimi qeyd et

### 4. MÉ™lumat KeyfiyyÉ™tinin YoxlanmasÄ±

```python
valid_timestamps = self.df['ts'].notna()
if not valid_timestamps.all():
    invalid_count = (~valid_timestamps).sum()
    logger.warning(f"Found {invalid_count} records with invalid timestamps")
    self.df = self.df[valid_timestamps]
```

**Funksiya:** EtibarsÄ±z timestamplÉ™ri filtrlÉ™yir vÉ™ xÉ™bÉ™rdarlÄ±q verir

### 5. DataFrame Indexinin TÉ™yin EdilmÉ™si

```python
self.df.set_index('ts', inplace=True)
```

**Funksiya:** Timestamp sÃ¼tununu DataFrame'in indexi kimi tÉ™yin edir

**ÆhÉ™miyyÉ™ti:** Vaxt É™saslÄ± sorÄŸular vÉ™ filtrlÉ™mÉ™ Ã¼Ã§Ã¼n vacibdir

### 6. Vaxt PÉ™ncÉ™rÉ™si FiltrlÉ™mÉ™si

```python
if days is not None:
    cutoff_time = datetime.now() - pd.Timedelta(days=days)
    self.df = self.df[self.df.index >= cutoff_time]
```

**Funksiya:** MÃ¼É™yyÉ™n gÃ¼n sayÄ±na gÃ¶rÉ™ mÉ™lumatlarÄ± filtrlÉ™yir

### 7. MÉ™lumat KeyfiyyÉ™tinin YoxlanmasÄ±

```python
self._validate_data_quality()
```

**Funksiya:** MÉ™lumatÄ±n tamlÄ±ÄŸÄ±nÄ± vÉ™ keyfiyyÉ™tini yoxlayÄ±r

## ğŸ“Š MÉ™lumat Strukturu

**Oxunan mÉ™lumatÄ±n nÃ¼munÉ™ strukturu:**

| ts | id.orig_h | id.resp_h | query | qtype_name | rcode_name |
|----|-----------|-----------|-------|------------|------------|
| 2024-01-15 10:30:00 | 192.168.1.100 | 8.8.8.8 | google.com | A | NOERROR |
| 2024-01-15 10:30:01 | 192.168.1.101 | 1.1.1.1 | example.com | AAAA | NXDOMAIN |

## âš ï¸ XÉ™ta ÆlaqÉ™lÉ™ndirmÉ™

Metod aÅŸaÄŸÄ±dakÄ± xÉ™talarÄ± idarÉ™ edir:

1. **Fayl oxuma xÉ™talarÄ±** - `IOError`, `PermissionError`
2. **Data parsing xÉ™talarÄ±** - `pd.errors.ParserError`
3. **Timestamp konversiya xÉ™talarÄ±** - `ValueError`
4. **YaddaÅŸ xÉ™talarÄ±** - `MemoryError`

**XÉ™ta handling strategiyasÄ±:** HÉ™r bir xÉ™ta `try-catch` bloku ilÉ™ idarÉ™ olunur vÉ™ `False` qaytarÄ±lÄ±r

## ğŸ¯ Ä°stifadÉ™ NÃ¼munÉ™lÉ™ri

### Æsas Ä°stifadÉ™
```python
parser = ZeekLogParser("config.json")

# Son 7 gÃ¼nlÃ¼k mÉ™lumatÄ± oxumaq
success = parser.read_historical(days=7)
if success:
    print(f"UÄŸurla oxundu: {len(parser.df)} qeyd")
else:
    print("Oxuma uÄŸursuz oldu")

# BÃ¼tÃ¼n mÃ¶vcud mÉ™lumatÄ± oxumaq
success = parser.read_historical()  # days=None
```

### MÉ™lumat Analizi
```python
if parser.read_historical(days=1):
    # StatistikalarÄ± gÃ¶stÉ™rmÉ™k
    stats = parser.get_stats()
    print(f"Ãœmumi sorÄŸular: {stats['total_records']}")
    print(f"Unikal mÉ™nbÉ™lÉ™r: {stats['unique_sources']}")
    
    # Ä°lk 5 qeydi gÃ¶stÉ™rmÉ™k
    print(parser.df.head())
```

## ğŸš€ Performans OptimizasiyalarÄ±

### 1. YaddaÅŸ Ä°stifadÉ™si
```python
low_memory=False  # BÃ¶yÃ¼k fayllar Ã¼Ã§Ã¼n optimallaÅŸdÄ±rma
```

### 2. SÃ¼tun SeÃ§imi
```python
# YalnÄ±z lazÄ±mi sÃ¼tunlarÄ± oxumaq (gÉ™lÉ™cÉ™k inkiÅŸaf)
# usecols=['ts', 'id.orig_h', 'query', 'qtype_name']
```

### 3. Ã‡atlarÄ± Oxuma
```python
# BÃ¶yÃ¼k fayllar Ã¼Ã§Ã¼n chunk-based oxuma (gÉ™lÉ™cÉ™k inkiÅŸaf)
# chunksize=10000
```

## ğŸ” MÉ™lumat KeyfiyyÉ™ti YoxlamalarÄ±

Metod aÅŸaÄŸÄ±dakÄ± keyfiyyÉ™t yoxlamalarÄ±nÄ± hÉ™yata keÃ§irir:

1. **Vacib sÃ¼tunlarÄ±n mÃ¶vcudluÄŸu** - `id.orig_h`, `query`, `qtype_name`
2. **Ã‡atÄ±ÅŸmayan dÉ™yÉ™rlÉ™rin aÅŸkarlanmasÄ±** - NaN vÉ™ null dÉ™yÉ™rlÉ™r
3. **Timestamp etibarlÄ±lÄ±ÄŸÄ±** - EtibarsÄ±z zaman damÄŸalarÄ±
4. **Data tipi uyÄŸunluÄŸu** - GÃ¶zlÉ™nilÉ™n data tiplÉ™ri

## ğŸ“ˆ Metrik vÉ™ Statistikalar

Metod iÅŸlÉ™dikdÉ™n sonra aÅŸaÄŸÄ±dakÄ± statistikalar mÃ¶vcud olur:

```python
# NÃ¼munÉ™ Ã§Ä±xÄ±ÅŸ
print(f"Ãœmumi oxunan qeydlÉ™r: {len(parser.df)}")
print(f"Vaxt aralÄ±ÄŸÄ±: {parser.df.index.min()} - {parser.df.index.max()}")
print(f"Unikal IP Ã¼nvanlarÄ±: {parser.df['id.orig_h'].nunique()}")
print(f"Unikal domainlÉ™r: {parser.df['query'].nunique()}")
```

## ğŸ’¡ ÆlavÉ™ QeydlÉ™r

1. **Fayl Ã–lÃ§Ã¼sÃ¼:** Metod GB Ã¶lÃ§Ã¼lÃ¼ fayllarla iÅŸlÉ™yÉ™ bilir
2. **YaddaÅŸ Ä°stifadÉ™si:** BÃ¶yÃ¼k fayllar Ã¼Ã§Ã¼n É™lavÉ™ yaddaÅŸ tÉ™lÉ™b edÉ™ bilÉ™r
3. **Performans:** Oxuma sÃ¼rÉ™ti fayl Ã¶lÃ§Ã¼sÃ¼ndÉ™n vÉ™ sistem resurslarÄ±ndan asÄ±lÄ±dÄ±r
4. **Error Recovery:** XÉ™ta halÄ±nda avtomatik bÉ™rpa cÉ™hdlÉ™ri

---

**NÃ¶vbÉ™ti:** [03. Log Parser Modulu - tail_new_entries method](core/03_log_parser/04_tail_new_entries_method.md)

Bu sÉ™nÉ™d `read_historical` metodunun detallÄ± iÅŸlÉ™mÉ™ prinsipini izah edir. NÃ¶vbÉ™ti sÉ™nÉ™ddÉ™ real-time log oxuma metoduna keÃ§É™cÉ™yik.
